# RWKV-Infer
A large-scale RWKV v6 inference engine using the Cuda backend. Supports multi-batch generation and dynamic State switching. Let's spread RWKV, which combines RNN technology with impressively low inference costs!
